<<<<<<< HEAD
# BIGDATA_ENGINEERING_LABS

Ce d√©p√¥t contient les travaux pratiques de Big Data Engineering (ann√©e 2025-2026). Ci‚Äëdessous un bref r√©sum√© des trois labs pr√©sents dans le projet.
=======
# BIG DATA ENGINEERING ‚Äì Lab 1  
**Ann√©e universitaire : 2025-2026**  
**√âtudiant : Ahmed QAIS**

> Ce d√©p√¥t contient la r√©alisation du **Lab 1 : Programmation avec l‚ÄôAPI HDFS et MapReduce**, dans le cadre du cours de **Big Data Engineering**.

---

## üéØ Objectifs du TP

- ‚úÖ Manipuler les fichiers sur **HDFS** via l‚Äô**API Java Hadoop** :
  - Lire les m√©tadonn√©es d‚Äôun fichier (`HadoopFileStatus`)
  - Lire le contenu d‚Äôun fichier (`ReadHDFS`)
  - √âcrire un nouveau fichier (`WriteHDFS`)
- ‚úÖ Impl√©menter le classique **WordCount** en **Java (MapReduce)**.
- ‚úÖ R√©aliser le m√™me traitement en **Python** avec **Hadoop Streaming**.
- ‚úÖ Versionner le code avec **Git/GitHub**.

---
>>>>>>> 4e0dce7ec890cde44209dcbac98dcdd225227c6e
````markdown
# BIGDATA_ENGINEERING_LABS

**Ann√©e universitaire : 2025-2026**

Ce d√©p√¥t contient les travaux pratiques du cours Big Data Engineering. Voici un r√©sum√© organis√© des labos et √©l√©ments pr√©sents dans le projet.

## Vue d'ensemble

- `lab0/` : infrastructure Docker pour un petit cluster (master + slaves) avec `docker-compose.yml` pour d√©marrer les n≈ìuds et tester les montages de volumes partag√©s.
- `hadoop_lab/` : labs 1 & 2 ‚Äî travaux sur Hadoop/HDFS et MapReduce. Contient les sources Java, les exemples MapReduce et des scripts pour ex√©cution dans l'environnement Hadoop.
- `lab3_kafka/` : lab 3 ‚Äî exp√©rimentations Kafka. Contient le module `kafka_lab` avec producteurs/consommateurs Java, une app Kafka Streams (WordCount), des exemples Kafka Connect, et un `docker-compose.kafka-ui.yml` pour Kafka‚ÄëUI.

## Ce que j'ai impl√©ment√©

1. Infrastructure Docker (lab0)
  - `docker-compose.yml` pour d√©marrer `hadoop-master` et deux slaves. Le master expose un volume partag√© pour d√©poser des JARs et fichiers √† utiliser par les services du conteneur.

2. Hadoop / MapReduce (lab1 & lab2)
  - Exemples Java : utilitaires HDFS (`HadoopFileStatus`, `ReadHDFS`, `WriteHDFS`) et job WordCount en Java.
  - Exemple Python : mapper/reducer pour Hadoop Streaming.

3. Kafka (lab3)
  - Producteurs/consommateurs Java (`EventProducer`, `EventConsumer`), outils interactifs (`WordProducer`, `WordCountConsumer`).
  - Kafka Streams : `WordCountApp` (exemple stateful avec store local).
  - Kafka Connect examples (file source -> topic -> file sink) et compose pour Kafka‚ÄëUI.

## Pr√©requis

- Apache Hadoop 3.x
- Java 8
- Maven
- Docker (pour l'environnement avec `hadoop-master` et outils Kafka)

## Commandes utiles

### Compiler les projets Java
```powershell
cd lab3_kafka/kafka_lab
mvn clean package -DskipTests
```

### Ex√©cution des jobs Hadoop (exemples)
```powershell
# WordCount Java (ex√©cution depuis le conteneur master)
hadoop jar hadoop_lab/target/WordCount.jar /user/root/input/file.txt /user/root/output/wordcount

# Hadoop Streaming (Python)
hadoop jar /path/to/hadoop-streaming.jar -files mapper.py,reducer.py -mapper "python3 mapper.py" -reducer "python3 reducer.py" -input /user/root/input -output /user/root/output_python
```

## Notes et bonnes pratiques

- Les artefacts compil√©s (dossiers `target/`, JARs) ne devraient pas √™tre commit√©s dans le d√©p√¥t principal. Il est recommand√© d'ajouter `target/` √† `.gitignore` et de ne versionner que les sources et la documentation.
- Pour publier les JARs d'ex√©cution, utiliser les Releases GitHub ou un dossier partag√© externe plut√¥t que de committer les binaires dans `master`.

---
Auteur : Ahmed QAIS

````
